{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkIg75/knJvSzzCh4JRgRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahar-mariam/level2-report/blob/main/NaiveBayesianClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining whether a given passenger on the Titanic survived to the tragedy or not."
      ],
      "metadata": {
        "id": "VU8l6Ro3JJZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0edGuF7HfBv",
        "outputId": "729c9f7e-ff6e-49c2-aeaa-76b098d30167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "y = list(map(lambda v: 'yes' if v == 1 else 'no', data['Survived'].values)) # target values as string\n",
        "\n",
        "# We won't use the 'Name' nor the 'Fare' field\n",
        "\n",
        "X = data[['Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']].values # features values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y)) # >> 887\n",
        "\n",
        "# We'll take 600 examples to train and the rest to the validation process\n",
        "y_train = y[:600]\n",
        "y_val = y[600:]\n",
        "\n",
        "X_train = X[:600]\n",
        "X_val = X[600:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtVQlG2IIm3B",
        "outputId": "af058c57-720f-4b65-b3b9-4a1fd99d820c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"The code below defines a Naive Bayes classifier class. The classifier is trained on a set of features (X) and\n",
        " corresponding target labels (y). It then uses the trained model to classify new entries based on their features.\"\"\"\n",
        "\n",
        "\"\"\"The classify method takes an entry (a list of feature values) as input and returns the predicted label using the\n",
        "Naive Bayes classification algorithm.\n",
        "-solve stores the final predicted labels\n",
        "-max_arg stores the maximum probability encountered during classification.\n",
        "The method iterates over each output class (label) in self.output_dom and calculates the probability of that class\n",
        "given the entry features.\"\"\"\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "\n",
        "        '''\n",
        "        X and y denotes the features and the target labels respectively\n",
        "        '''\n",
        "        self.X, self.y = X, y\n",
        "\n",
        "        self.N = len(self.X) # Length of the training set\n",
        "\n",
        "        self.dim = len(self.X[0]) # Dimension of the vector of features\n",
        "\n",
        "        self.attrs = [[] for _ in range(self.dim)] # Here we'll store the columns of the training set\n",
        "\n",
        "        self.output_dom = {} # Output classes with the number of ocurrences in the training set. In this case we have only 2 classes\n",
        "\n",
        "        self.data = [] # To store every row [Xi, yi]\n",
        "\n",
        "\n",
        "        for i in range(len(self.X)):\n",
        "            for j in range(self.dim):\n",
        "                # if we have never seen this value for this attr before,\n",
        "                # then we add it to the attrs array in the corresponding position\n",
        "                if not self.X[i][j] in self.attrs[j]:\n",
        "                    self.attrs[j].append(self.X[i][j])\n",
        "\n",
        "            # if we have never seen this output class before,\n",
        "            # then we add it to the output_dom and count one occurrence for now\n",
        "            if not self.y[i] in self.output_dom.keys():\n",
        "                self.output_dom[self.y[i]] = 1\n",
        "            # otherwise, we increment the occurrence of this output in the training set by 1\n",
        "            else:\n",
        "                self.output_dom[self.y[i]] += 1\n",
        "            # store the row\n",
        "            self.data.append([self.X[i], self.y[i]])\n",
        "\n",
        "\n",
        "    def classify(self, entry):\n",
        "\n",
        "        solve = None # Final result\n",
        "        max_arg = -1 # partial maximum\n",
        "\n",
        "        for y in self.output_dom.keys():\n",
        "\n",
        "            prob = self.output_dom[y]/self.N # P(y)\n",
        "\n",
        "            for i in range(self.dim):\n",
        "                cases = [x for x in self.data if x[0][i] == entry[i] and x[1] == y] # all rows with Xi = xi\n",
        "                n = len(cases)\n",
        "                prob *= n/self.N # P *= P(Xi = xi)\n",
        "\n",
        "            # if we have a greater prob for this output than the partial maximum...\n",
        "            if prob > max_arg:\n",
        "                max_arg = prob\n",
        "                solve = y\n",
        "            return solve"
      ],
      "metadata": {
        "id": "m74aLv--I5Nu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"It then calculates the total number of cases in the validation set and stores it in the variable total_cases.\n",
        "The code enters a loop that iterates through each case in the validation set.\n",
        "For each case, it uses the classify method of the nbc object to predict the label based on the features X_val[i].\n",
        "If the predicted label predict matches the actual label y_val[i], it increments the good variable.\n",
        "Otherwise, it increments the bad variable.\"\"\"\n",
        "\n",
        "nbc = NaiveBayesClassifier(X_train, y_train)\n",
        "\n",
        "\n",
        "total_cases = len(y_val) # size of validation set\n",
        "\n",
        "# Well classified examples and bad classified examples\n",
        "good = 0\n",
        "bad = 0\n",
        "\n",
        "for i in range(total_cases):\n",
        "    predict = nbc.classify(X_val[i])\n",
        "#     print(y_val[i] + ' --------------- ' + predict)\n",
        "    if y_val[i] == predict:\n",
        "        good += 1\n",
        "    else:\n",
        "        bad += 1\n",
        "\n",
        "print('TOTAL EXAMPLES:', total_cases)\n",
        "print('RIGHT:', good)\n",
        "print('WRONG:', bad)\n",
        "print('ACCURACY:', good/total_cases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dVW1hnhIsIt",
        "outputId": "26703bd7-10c6-4fd4-cb24-0ed33349a272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL EXAMPLES: 287\n",
            "RIGHT: 182\n",
            "WRONG: 105\n",
            "ACCURACY: 0.6341463414634146\n"
          ]
        }
      ]
    }
  ]
}