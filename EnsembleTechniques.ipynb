{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeKNE0kb7bCubhnhrHf0Du",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahar-mariam/level2-report/blob/main/EnsembleTechniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble techniques applied to the Titanic dataset for predicting survival or no survival.\n",
        "- using two popular ensemble methods: Random Forest and Gradient Boosting (using XGBoost)\n",
        "- importing scikit-learn and XGBoost libraries."
      ],
      "metadata": {
        "id": "cv64lPl3VCTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTYN1MCpHs2o"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries with warnings filter\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "titanic_data = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing:\n",
        "- Removing unnecessary columns (Name, Ticket, Cabin, PassengerId).\n",
        "- Performing one-hot encoding for categorical variables.\n",
        "- Dropping rows with missing values.\n",
        "\n",
        "Splitting the Data:\n",
        "- Separating the data into features (X) and the target variable (y).\n",
        "- Splitting the data into training and testing sets."
      ],
      "metadata": {
        "id": "iOZxfw0nT5Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "titanic_data = titanic_data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)  # Drop unnecessary columns\n",
        "titanic_data = pd.get_dummies(titanic_data, drop_first=True)  # One-hot encoding for categorical variables\n",
        "titanic_data = titanic_data.dropna()  # Drop rows with missing values\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = titanic_data.drop('Survived', axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HVpOShR4Ny7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Model:\n",
        "- Hyperparameter tuning using GridSearchCV.\n",
        "- Training the Random Forest model with the best parameters.\n",
        "- Cross-validation scores and model evaluation.\n"
      ],
      "metadata": {
        "id": "2Ou8_w3aUR4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble 1: Random Forest\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param_grid, cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from the grid search\n",
        "best_rf_params = rf_grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model with the best parameters\n",
        "rf_model = RandomForestClassifier(random_state=42, **best_rf_params)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation scores\n",
        "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
        "print(f\"Random Forest Cross-Validation Scores: {rf_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score: {rf_cv_scores.mean()}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "print(\"Random Forest Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, rf_predictions)}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcS7R5c8OBE8",
        "outputId": "ccb441ae-efc9-4389-dc52-9329a2cdd6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Cross-Validation Scores: [0.8173913  0.84210526 0.85087719 0.89473684 0.8245614 ]\n",
            "Mean Cross-Validation Score: 0.8459344012204424\n",
            "Random Forest Model Evaluation:\n",
            "Accuracy: 0.7972027972027972\n",
            "Confusion Matrix:\n",
            " [[75 12]\n",
            " [17 39]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84        87\n",
            "           1       0.76      0.70      0.73        56\n",
            "\n",
            "    accuracy                           0.80       143\n",
            "   macro avg       0.79      0.78      0.78       143\n",
            "weighted avg       0.80      0.80      0.80       143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Model:\n",
        "- Hyperparameter tuning using GridSearchCV.\n",
        "- Training the XGBoost model with the best parameters.\n",
        "- Cross-validation scores and model evaluation."
      ],
      "metadata": {
        "id": "d3z3wKaeUZGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble 2: XGBoost\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "xgb_grid_search = GridSearchCV(XGBClassifier(random_state=42), param_grid=xgb_param_grid, cv=5)\n",
        "xgb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from the grid search\n",
        "best_xgb_params = xgb_grid_search.best_params_\n",
        "\n",
        "# Train the XGBoost model with the best parameters\n",
        "xgb_model = XGBClassifier(random_state=42, **best_xgb_params)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation scores\n",
        "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5)\n",
        "print(f\"\\nXGBoost Cross-Validation Scores: {xgb_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score: {xgb_cv_scores.mean()}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "print(\"\\nXGBoost Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, xgb_predictions)}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, xgb_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA4SbM3GOBN7",
        "outputId": "c5930952-48ac-472b-bb39-46a28143bf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost Cross-Validation Scores: [0.8173913  0.85964912 0.85964912 0.86842105 0.84210526]\n",
            "Mean Cross-Validation Score: 0.8494431731502671\n",
            "\n",
            "XGBoost Model Evaluation:\n",
            "Accuracy: 0.8181818181818182\n",
            "Confusion Matrix:\n",
            " [[75 12]\n",
            " [14 42]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85        87\n",
            "           1       0.78      0.75      0.76        56\n",
            "\n",
            "    accuracy                           0.82       143\n",
            "   macro avg       0.81      0.81      0.81       143\n",
            "weighted avg       0.82      0.82      0.82       143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Model:\n",
        "- Combining predictions using a simple voting ensemble.\n",
        "- Model evaluation for the ensemble.\n",
        "\n"
      ],
      "metadata": {
        "id": "VYYSQKkLUr1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine predictions using a simple voting ensemble\n",
        "ensemble_predictions = (rf_predictions + xgb_predictions) // 2\n",
        "\n",
        "# Ensemble Model Evaluation\n",
        "print(\"\\nEnsemble Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, ensemble_predictions)}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, ensemble_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, ensemble_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKrYeS4SUfof",
        "outputId": "20746d23-7ca4-4385-8367-7b132f802ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Model Evaluation:\n",
            "Accuracy: 0.8111888111888111\n",
            "Confusion Matrix:\n",
            " [[77 10]\n",
            " [17 39]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85        87\n",
            "           1       0.80      0.70      0.74        56\n",
            "\n",
            "    accuracy                           0.81       143\n",
            "   macro avg       0.81      0.79      0.80       143\n",
            "weighted avg       0.81      0.81      0.81       143\n",
            "\n"
          ]
        }
      ]
    }
  ]
}